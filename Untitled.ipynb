{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 11 15:02:12 2018       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce GTX 108...  On   | 00000000:04:00.0 Off |                  N/A |\n",
      "| 23%   28C    P0    68W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  GeForce GTX 108...  On   | 00000000:06:00.0 Off |                  N/A |\n",
      "| 23%   27C    P8    16W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla P40           On   | 00000000:07:00.0 Off |                    0 |\n",
      "| N/A   23C    P8     9W / 250W |      0MiB / 22919MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  GeForce GTX 108...  On   | 00000000:08:00.0 Off |                  N/A |\n",
      "| 23%   28C    P8    16W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  GeForce GTX 108...  On   | 00000000:0C:00.0 Off |                  N/A |\n",
      "| 23%   28C    P8    16W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  GeForce GTX 108...  On   | 00000000:0D:00.0 Off |                  N/A |\n",
      "| 23%   26C    P8    15W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  GeForce GTX 108...  On   | 00000000:0E:00.0 Off |                  N/A |\n",
      "| 23%   27C    P8    15W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  GeForce GTX 108...  On   | 00000000:0F:00.0 Off |                  N/A |\n",
      "| 23%   28C    P8    16W / 250W |      0MiB / 11178MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy15923/.conda/envs/tf18_keras/lib/python3.6/site-packages/skimage/util/dtype.py:130: UserWarning: Possible precision loss when converting from uint8 to bool\n",
      "  .format(dtypeobj_in, dtypeobj_out))\n",
      "/home/jimmy15923/.conda/envs/tf18_keras/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "/home/jimmy15923/.conda/envs/tf18_keras/lib/python3.6/site-packages/skimage/transform/_warps.py:110: UserWarning: Anti-aliasing will be enabled by default in skimage 0.15 to avoid aliasing artifacts when down-sampling images.\n",
      "  warn(\"Anti-aliasing will be enabled by default in skimage 0.15 to \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape:\n",
      "(733, 512, 512, 3)\n",
      "(184, 512, 512, 3)\n",
      "(733, 512, 512)\n",
      "(184, 512, 512)\n",
      "Epoch 1/3\n",
      "1/2 [==============>...............] - ETA: 6s - loss: 0.7680\n",
      "Epoch 00001: val_loss improved from inf to 0.59766, saving model to test_resize.h5\n",
      "2/2 [==============================] - 17s 9s/step - loss: 0.7184 - val_loss: 0.5977\n",
      "Epoch 2/3\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.5967\n",
      "Epoch 00002: val_loss improved from 0.59766 to 0.36989, saving model to test_resize.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.5525 - val_loss: 0.3699\n",
      "Epoch 3/3\n",
      "1/2 [==============>...............] - ETA: 0s - loss: 0.4009\n",
      "Epoch 00003: val_loss improved from 0.36989 to 0.12817, saving model to test_resize.h5\n",
      "2/2 [==============================] - 8s 4s/step - loss: 0.2839 - val_loss: 0.1282\n",
      "TESTING IOU:  0.02363068124522332\n",
      "----------\n",
      "Elapse time: 125.30961060523987\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "# sys.path.append('keras-deeplab-v3-plus/')\n",
    "# from deeplab_v3_plus.model import *\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import skimage\n",
    "from skimage import io, img_as_bool\n",
    "from skimage.transform import resize\n",
    "\n",
    "# config\n",
    "crop_size = 512\n",
    "\n",
    "def get_unet():\n",
    "  \n",
    "    inputs = tf.keras.layers.Input((crop_size, crop_size, 3))\n",
    "    \n",
    "    conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(inputs)\n",
    "    conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(pool1)\n",
    "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(pool2)\n",
    "    conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(conv3)\n",
    "    pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(pool3)\n",
    "    conv4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(conv4)\n",
    "    pool4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(pool4)\n",
    "    conv5 = tf.keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(conv5)\n",
    "\n",
    "    up6 = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(64, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv5), conv4], axis=3)\n",
    "    conv6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(up6)\n",
    "    conv6 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(conv6)\n",
    "\n",
    "    up7 = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(32, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv6), conv3], axis=3)\n",
    "    conv7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(up7)\n",
    "    conv7 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(conv7)\n",
    "\n",
    "    up8 = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(16, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv7), conv2], axis=3)\n",
    "    conv8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(up8)\n",
    "    conv8 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(conv8)\n",
    "\n",
    "    up9 = tf.keras.layers.concatenate([tf.keras.layers.Conv2DTranspose(8, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv8), conv1], axis=3)\n",
    "    \n",
    "    conv9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(up9)\n",
    "    conv9 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(conv9)\n",
    "\n",
    "    conv10 = tf.keras.layers.Conv2D(2, (1, 1), activation='softmax')(conv9)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model\n",
    "\n",
    "def read_data_and_split(split_seed, train_ratio, is_normalize=True, is_resize=crop_size):\n",
    "    \"\"\"read data into np array, normalize it and train test split\n",
    "    \n",
    "    split_seed: set seed for same train test split\n",
    "    train_ratio: ratio of training set. range from 0 to 1\n",
    "    is_normalize: True for normalizr to -1 to 1\n",
    "    \n",
    "    return: x_train, x_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = next(os.walk('dataset/'))[1]\n",
    "    # remove two file with different size between image & mask\n",
    "    idx.remove(\"S2016-30816_9_0\")\n",
    "    idx.remove(\"S2016-30816_9_1\")\n",
    "    \n",
    "    # set seed\n",
    "    random.seed(split_seed)\n",
    "    random.shuffle(idx)\n",
    "    \n",
    "    train_idx, test_idx = idx[:int(len(idx)*train_ratio)], idx[int(len(idx)*train_ratio):]\n",
    "\n",
    "    x_train = np.array([skimage.io.imread('dataset/{}/image/{}_slide.jpg'.format(x, x))\\\n",
    "                    for x in train_idx], dtype=\"float32\")\n",
    "    x_test = np.array([skimage.io.imread('dataset/{}/image/{}_slide.jpg'.format(x, x))\\\n",
    "                       for x in test_idx], dtype=\"float32\")\n",
    "    \n",
    "    if is_normalize:\n",
    "        x_train = (x_train / 127.5) - 1\n",
    "        x_test = (x_test / 127.5) - 1\n",
    "        \n",
    "    y_train = np.array([skimage.io.imread('dataset/{}/mask/{}_mask.jpg'.format(x, x))[..., 0]\\\n",
    "                    for x in train_idx])\n",
    "    \n",
    "    y_test = np.array([skimage.io.imread('dataset/{}/mask/{}_mask.jpg'.format(x, x))[..., 0]\\\n",
    "                        for x in test_idx])\n",
    "    \n",
    "    y_train = img_as_bool(y_train)\n",
    "    y_test = img_as_bool(y_test)\n",
    "    \n",
    "    def cv2_resize(array):\n",
    "        return np.array([resize(x, (crop_size, crop_size)) for x in array])\n",
    "    \n",
    "    if is_resize:\n",
    "        x_train, x_test, y_train, y_test = cv2_resize(x_train), cv2_resize(x_test), cv2_resize(y_train), cv2_resize(y_test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def data_gen(x_train, y_train, bz, augmentation=None):\n",
    "    i = 0\n",
    "    from sklearn.utils import shuffle\n",
    "    while True:\n",
    "        if i == len(y_train):\n",
    "            i = 0\n",
    "            x_train, y_train = shuffle(x_train, y_train)\n",
    "            \n",
    "        x_, y_ = x_train[i*bz:(i+1)*bz], y_train[i*bz:(i+1)*bz]\n",
    "#         img_idx = np.random.choice(range(len(y_train)), bz, replace=False)\n",
    "        i += 1\n",
    "        yield x_, y_\n",
    "        \n",
    "def IOU_cal(y_true, y_pred):\n",
    "    iou_res = []\n",
    "    for i in range(len(y_true)):\n",
    "        y_true_flat = y_true[i].ravel()\n",
    "        y_pred_flat = (y_pred[i][...,1].ravel() > 0.5) * 1\n",
    "        intersection = np.sum(y_true_flat * y_pred_flat)\n",
    "        union = np.sum((y_true_flat+y_pred_flat) - (y_true_flat*y_pred_flat))\n",
    "        iou = intersection / union\n",
    "        iou_res.append(iou)\n",
    "    return iou_res        \n",
    "# def val_gen(x_test, y_test, crop_size=500, stride=500):\n",
    "#     i = 0\n",
    "#     while True:\n",
    "#         x = []\n",
    "#         y = []\n",
    "#         for x_start in range(0, crop_size+1, stride):\n",
    "#             for y_start in range(0, crop_size+1, stride):\n",
    "#                 x_crop = x_test[i][x_start:(x_start+crop_size), y_start:(y_start+crop_size), :]\n",
    "#                 y_crop = y_test[i][x_start:(x_start+crop_size), y_start:(y_start+crop_size), :]\n",
    "#                 x.append(x_crop)\n",
    "#                 y.append(y_crop)\n",
    "#         i+=1\n",
    "#         yield np.array(x), np.array(y)\n",
    "#         if i == len(y_test):\n",
    "#             i=0\n",
    "\n",
    "\n",
    "    \n",
    "x_train, x_test, y_train, y_test = read_data_and_split(split_seed=7, train_ratio=0.8)\n",
    "\n",
    "y_train_inv = np.where(y_train, 0, 1)\n",
    "y_train_ = np.zeros(shape=(len(y_train), crop_size, crop_size, 2))\n",
    "y_train_[:,:,:,0] = y_train\n",
    "y_train_[:,:,:,1] = y_train_inv\n",
    "\n",
    "y_test_inv = np.where(y_test, 0, 1)\n",
    "y_test_ = np.zeros(shape=(len(y_test), crop_size, crop_size, 2))\n",
    "y_test_[:,:,:,0] = y_test\n",
    "y_test_[:,:,:,1] = y_test_inv\n",
    "\n",
    "print(\"Data shape:\")\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "#     model = Deeplabv3(input_shape=(crop_size, crop_size, 3), classes=2, OS=8)\n",
    "#     logits = model.output\n",
    "#     output = tf.keras.layers.Activation(\"softmax\")(logits)\n",
    "#     model = tf.keras.models.Model(model.input, output)\n",
    "\n",
    "model = get_unet()\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred, smooth=1):\n",
    "    def dice_coef_fix(y_true, y_pred):\n",
    "        intersection = K.sum(K.abs(y_true * y_pred), axis = -1)\n",
    "        iou = (2. * intersection + smooth) / (K.sum(K.square(y_true), -1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "        return iou\n",
    "    loss = 1 - dice_coef_fix(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "#     model_gpu = tf.keras.utils.multi_gpu_model(model, gpus=args.num_gpus)\n",
    "\n",
    "model.compile(optimizer=\"Adam\",\n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "early = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, verbose=1)\n",
    "check = tf.keras.callbacks.ModelCheckpoint(monitor=\"val_loss\",\n",
    "                                        filepath=\"test_resize.h5\",\n",
    "                                        verbose=1, save_best_only=True)\n",
    "\n",
    "reduce = tf.keras.callbacks.ReduceLROnPlateau(patience=3)\n",
    "\n",
    "t = time.time()\n",
    "model.fit_generator(data_gen(x_train, y_train_, 12),\n",
    "                    steps_per_epoch=2,\n",
    "                    epochs=3, \n",
    "                    validation_data=(x_test, y_test_),\n",
    "                    callbacks=[early, check, reduce]\n",
    "                   )\n",
    "model = tf.keras.models.load_model(\"test_resize.h5\")\n",
    "## inference\n",
    "_, x_test, _, y_test = read_data_and_split(split_seed=7, train_ratio=0.8, is_resize=1000)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "res_iou = IOU_cal(y_test, y_pred)\n",
    "print(\"TESTING IOU: \",np.mean(res_iou))\n",
    "print(\"-\"*10)\n",
    "print(\"Elapse time:\", time.time() - t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.14.0'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skimage.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU_cal(y_true, y_pred):\n",
    "    iou_res = []\n",
    "    for i in range(len(y_true)):\n",
    "        y_true_flat = y_true[i].ravel()\n",
    "        y_pred_flat = (y_pred[i][...,0].ravel() > 0.5) * 1\n",
    "        intersection = np.sum(y_true_flat * y_pred_flat)\n",
    "        union = np.sum((y_true_flat+y_pred_flat) - (y_true_flat*y_pred_flat))\n",
    "        iou = intersection / union\n",
    "        iou_res.append(iou)\n",
    "    return iou_res  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy15923/.local/lib/python3.6/site-packages/ipykernel/__main__.py:8: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING IOU:  nan\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "res_iou = IOU_cal(y_test, y_pred)\n",
    "print(\"TESTING IOU: \",np.mean(res_iou))\n",
    "print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.models.load_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf18_keras]",
   "language": "python",
   "name": "conda-env-tf18_keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
