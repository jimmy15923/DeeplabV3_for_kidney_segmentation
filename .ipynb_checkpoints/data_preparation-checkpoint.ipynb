{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "\n",
    "import os\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import random\n",
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.training_utils import multi_gpu_model\n",
    "\n",
    "import sys\n",
    "sys.path.append('keras-deeplab-v3-plus/')\n",
    "from deeplab_v3_plus.model import *\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "from skimage import img_as_bool\n",
    "\n",
    "def read_data_and_split(split_seed, train_ratio, is_normalize=True):\n",
    "    \"\"\"read data into np array, normalize it and train test split\n",
    "    split_seed: set seed for same train test split\n",
    "    train_ratio: ratio of training set. range from 0 to 1\n",
    "    is_normalize: True for normalizr to -1 to 1\n",
    "    \n",
    "    return np array with x_train, x_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = next(os.walk('/data/jimmy15923/cg_kidney_seg/train'))[1]\n",
    "    # remove two file with different size between image & mask\n",
    "    idx.remove(\"S2016-30816_9_0\")\n",
    "    idx.remove(\"S2016-30816_9_1\")\n",
    "    \n",
    "    # set seed\n",
    "    random.seed(split_seed)\n",
    "    random.shuffle(idx)\n",
    "    \n",
    "    train_idx, test_idx = idx[:int(len(idx)*train_ratio)], idx[int(len(idx)*train_ratio):]\n",
    "\n",
    "    x_train = np.array([cv2.imread('/data/jimmy15923/cg_kidney_seg/train/{}/image/{}_slide.jpg'.format(x, x))[...,::-1]\\\n",
    "                    for x in train_idx], dtype=\"float32\")\n",
    "    x_test = np.array([cv2.imread('/data/jimmy15923/cg_kidney_seg/train/{}/image/{}_slide.jpg'.format(x, x))[...,::-1]\\\n",
    "                       for x in test_idx], dtype=\"float32\")\n",
    "    \n",
    "    if is_normalize:\n",
    "        x_train = (x_train / 127.5) - 1\n",
    "        x_test = (x_test / 127.5) - 1\n",
    "        \n",
    "    y_train = np.array([cv2.imread('/data/jimmy15923/cg_kidney_seg/train/{}/mask/{}_mask.jpg'.format(x, x))[..., 0]\\\n",
    "                    for x in train_idx])\n",
    "    \n",
    "    y_test = np.array([cv2.imread('/data/jimmy15923/cg_kidney_seg/train/{}/mask/{}_mask.jpg'.format(x, x))[..., 0]\\\n",
    "                        for x in test_idx])\n",
    "    \n",
    "    y_train = img_as_bool(y_train)\n",
    "    y_test = img_as_bool(y_test)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "def cv2_resize(array):\n",
    "    return np.array([resize(x, (500,500)) for x in array])\n",
    "\n",
    "x_train, x_test, y_train, y_test = read_data_and_split(split_seed=7, train_ratio=0.8, is_normalize=True)\n",
    "\n",
    "x_train = cv2_resize(x_train)\n",
    "x_test = cv2_resize(x_test)\n",
    "y_train = cv2_resize(y_train)\n",
    "y_test = cv2_resize(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "y_train_inv = np.where(y_train, 0, 1)\n",
    "y_train_ = np.zeros(shape=(len(y_train), 500,500, 2))\n",
    "y_train_[:,:,:,0] = y_train\n",
    "y_train_[:,:,:,1] = y_train_inv\n",
    "\n",
    "y_test_inv = np.where(y_test, 0, 1)\n",
    "y_test_ = np.zeros(shape=(len(y_test), 500,500, 2))\n",
    "y_test_[:,:,:,0] = y_test\n",
    "y_test_[:,:,:,1] = y_test_inv\n",
    "\n",
    "def data_gen(x_train, y_train, bz, augmentation=None):\n",
    "    i = 0\n",
    "    from sklearn.utils import shuffle\n",
    "    while True:\n",
    "#         if i == len(y_train):\n",
    "#             i = 0\n",
    "#             x_train, y_train = shuffle(x_train, y_train)\n",
    "            \n",
    "#         x_, y_ = x_train[i*bz:(i+1)*bz], y_train[i*bz:(i+1)*bz]\n",
    "        img_idx = np.random.choice(range(len(y_train)), bz, replace=False)\n",
    "        \n",
    "\n",
    "        yield x_train[img_idx], y_train[img_idx]\n",
    "        \n",
    "# def val_gen(x_test, y_test, crop_size=500, stride=500):\n",
    "#     i = 0\n",
    "#     while True:\n",
    "#         x = []\n",
    "#         y = []\n",
    "#         for x_start in range(0, crop_size+1, stride):\n",
    "#             for y_start in range(0, crop_size+1, stride):\n",
    "#                 x_crop = x_test[i][x_start:(x_start+crop_size), y_start:(y_start+crop_size), :]\n",
    "#                 y_crop = y_test[i][x_start:(x_start+crop_size), y_start:(y_start+crop_size), :]\n",
    "#                 x.append(x_crop)\n",
    "#                 y.append(y_crop)\n",
    "#         i+=1\n",
    "#         yield np.array(x), np.array(y)\n",
    "#         if i == len(y_test):\n",
    "#             i=0\n",
    "\n",
    "crop_size = 500\n",
    "model = Deeplabv3(input_shape=(crop_size, crop_size, 3), classes=2, OS=8)\n",
    "logits = model.output\n",
    "output = keras.layers.Activation(\"softmax\")(logits)\n",
    "model = Model(model.input, output)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred, smooth = 1):\n",
    "    def dice_coef_fix(y_true, y_pred):\n",
    "        intersection = K.sum(K.abs(y_true * y_pred), axis = -1)\n",
    "        iou = (2. * intersection + smooth) / (K.sum(K.square(y_true), -1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "        return iou\n",
    "    loss = 1 - dice_coef_fix(y_true, y_pred)\n",
    "    return loss\n",
    "\n",
    "model_gpu = multi_gpu_model(model, gpus=2)\n",
    "\n",
    "model_gpu.compile(optimizer=keras.optimizers.SGD(lr=1e-4, momentum=0.9, nesterov=True),\n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, verbose=1)\n",
    "check = keras.callbacks.ModelCheckpoint(monitor=\"val_loss\",\n",
    "                                        filepath=\"/data/jimmy15923/cg_kidney_seg/test_resize.h5\",\n",
    "                                        verbose=1, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "reduce = keras.callbacks.ReduceLROnPlateau(patience=3)\n",
    "\n",
    "\n",
    "model_gpu.fit_generator(data_gen(x_train, y_train_, 12),\n",
    "                    steps_per_epoch=200,\n",
    "                    epochs=1000, \n",
    "                    validation_data=(x_test, y_test_),\n",
    "                    callbacks=[early, check, reduce]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('keras-deeplab-v3-plus/')\n",
    "from deeplab_v3_plus.model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### code for prepare raw data\n",
    "# image_list = glob.glob(\"/mnt/dataset/mask_roi/*.jpg\")\n",
    "\n",
    "# !rm -r /data/jimmy15923/cg_kidney_seg/\n",
    "\n",
    "# !mkdir /data/jimmy15923/cg_kidney_seg\n",
    "\n",
    "# for idx in set(all_idx):\n",
    "#     os.makedirs(\"/data/jimmy15923/cg_kidney_seg/{}/mask/\".format(idx))\n",
    "#     os.makedirs(\"/data/jimmy15923/cg_kidney_seg/{}/image/\".format(idx))\n",
    "\n",
    "# for img in image_list:\n",
    "#     name = os.path.basename(img)[:-4]\n",
    "#     if \"2018\" in name:\n",
    "#         new = name.split(\" \")[2]\n",
    "#     else:\n",
    "#         new = name\n",
    "#     if \"mask\" in new:\n",
    "#         idx = new.split(\"_\")[0] + \"_\" + new.split(\"_\")[3] + \"_\" + new.split(\"_\")[4] \n",
    "#     else:\n",
    "#         idx = new.split(\"_\")[0] + \"_\" + new.split(\"_\")[2] + \"_\" + new.split(\"_\")[3]  \n",
    "\n",
    "#     if \"mask\" in new:\n",
    "#         shutil.copy2(img, '/data/jimmy15923/cg_kidney_seg/{}/mask/{}_mask.jpg'.format(idx, idx))\n",
    "#     else:\n",
    "#         shutil.copy2(img, '/data/jimmy15923/cg_kidney_seg/{}/image/{}_slide.jpg'.format(idx, idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "def read_data_and_split(split_seed, train_ratio, is_normalize=True):\n",
    "    \"\"\"read data into np array, normalize it and train test split\n",
    "    split_seed: set seed for same train test split\n",
    "    train_ratio: ratio of training set. range from 0 to 1\n",
    "    is_normalize: True for normalizr to -1 to 1\n",
    "    \n",
    "    return np array with x_train, x_test, y_train, y_test\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = next(os.walk('/data/jimmy15923/cg_kidney_seg/train'))[1]\n",
    "    # remove two file with different size between image & mask\n",
    "    idx.remove(\"S2016-30816_9_0\")\n",
    "    idx.remove(\"S2016-30816_9_1\")\n",
    "    \n",
    "    # set seed\n",
    "    random.seed(split_seed)\n",
    "    random.shuffle(idx)\n",
    "    \n",
    "    train_idx, test_idx = idx[:int(len(idx)*train_ratio)], idx[int(len(idx)*train_ratio):]\n",
    "\n",
    "    x_train = np.array([cv2.imread('/data/jimmy15923/cg_kidney_seg/train/{}/image/{}_slide.jpg'.format(x, x))[...,::-1]\\\n",
    "                    for x in train_idx], dtype=\"float32\")\n",
    "    x_test = np.array([cv2.imread('/data/jimmy15923/cg_kidney_seg/train/{}/image/{}_slide.jpg'.format(x, x))[...,::-1]\\\n",
    "                       for x in test_idx], dtype=\"float32\")\n",
    "    \n",
    "    if is_normalize:\n",
    "        x_train = (x_train / 127.5) - 1\n",
    "        x_test = (x_test / 127.5) - 1\n",
    "        \n",
    "    y_train = np.array([cv2.imread('/data/jimmy15923/cg_kidney_seg/train/{}/mask/{}_mask.jpg'.format(x, x))[..., 0]\\\n",
    "                    for x in train_idx])\n",
    "    \n",
    "    y_test = np.array([cv2.imread('/data/jimmy15923/cg_kidney_seg/train/{}/mask/{}_mask.jpg'.format(x, x))[..., 0]\\\n",
    "                        for x in test_idx])\n",
    "    \n",
    "    y_train = y_train.astype(np.bool)*1\n",
    "    y_test = y_test.astype(np.bool)*1\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "x_train, x_test, y_train, y_test = read_data_and_split(split_seed=7, train_ratio=0.8, is_normalize=True)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(y_train))\n",
    "plt.subplot(121)\n",
    "plt.imshow(y_train[idx])\n",
    "plt.subplot(122)\n",
    "tmp = y_train[idx].astype(np.bool) * 1\n",
    "plt.imshow(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_inv = np.where(y_train, 0, 1)\n",
    "y_train_ = np.zeros(shape=(len(y_train), 1000,1000, 2))\n",
    "y_train_[:,:,:,0] = y_train\n",
    "y_train_[:,:,:,1] = y_train_inv\n",
    "\n",
    "y_test_inv = np.where(y_test, 0, 1)\n",
    "y_test_ = np.zeros(shape=(len(y_test), 1000,1000, 2))\n",
    "y_test_[:,:,:,0] = y_test\n",
    "y_test_[:,:,:,1] = y_test_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(y_train))\n",
    "plt.subplot(121)\n",
    "plt.imshow(y_train_[idx][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y_train_[idx][:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if augmentation:\n",
    "        import imgaug\n",
    "\n",
    "        # Augmentors that are safe to apply to masks\n",
    "        # Some, such as Affine, have settings that make them unsafe, so always\n",
    "        # test your augmentation on masks\n",
    "        MASK_AUGMENTERS = [\"Sequential\", \"SomeOf\", \"OneOf\", \"Sometimes\",\n",
    "                           \"Fliplr\", \"Flipud\", \"CropAndPad\",\n",
    "                           \"Affine\", \"PiecewiseAffine\"]\n",
    "\n",
    "        def hook(images, augmenter, parents, default):\n",
    "            \"\"\"Determines which augmenters to apply to masks.\"\"\"\n",
    "            return (augmenter.__class__.__name__ in MASK_AUGMENTERS)\n",
    "\n",
    "        # Store shapes before augmentation to compare\n",
    "        image_shape = image.shape\n",
    "        mask_shape = mask.shape\n",
    "        # Make augmenters deterministic to apply similarly to images and masks\n",
    "        det = augmentation.to_deterministic()\n",
    "        image = det.augment_image(image)\n",
    "        # Change mask to np.uint8 because imgaug doesn't support np.bool\n",
    "        mask = det.augment_image(mask.astype(np.uint8),\n",
    "                                 hooks=imgaug.HooksImages(activator=hook))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(x_train, y_train, crop_size, bz, augmentation=None):\n",
    "    while True:\n",
    "        x = []\n",
    "        y = []\n",
    "        img_idx = np.random.choice(range(len(y_train)), bz, replace=False)\n",
    "        for idx in img_idx:\n",
    "            \n",
    "            x_mid = np.random.choice(range(1000-(crop_size)), 1)[0] \n",
    "            y_mid = np.random.choice(range(1000-(crop_size)), 1)[0]\n",
    "#             tmp_x = np.pad(x_train[idx], 1, mode='constant')\n",
    "#             tmp_y = np.pad(y_train[idx], 1, mode='constant')\n",
    "            x_ = x_train[idx][(x_mid):(x_mid+(crop_size)), (y_mid):(y_mid+(crop_size))]\n",
    "            y_ = y_train[idx][(x_mid):(x_mid+(crop_size)), (y_mid):(y_mid+(crop_size))]\n",
    "            if augmentation:\n",
    "                import imgaug\n",
    "                # Augmentors that are safe to apply to masks\n",
    "                # Some, such as Affine, have settings that make them unsafe, so always\n",
    "                # test your augmentation on masks\n",
    "                MASK_AUGMENTERS = [\"Sequential\", \"SomeOf\", \"OneOf\", \"Sometimes\",\n",
    "                                   \"Fliplr\", \"Flipud\", \"CropAndPad\",\n",
    "                                   \"Affine\", \"PiecewiseAffine\"]\n",
    "\n",
    "                def hook(images, augmenter, parents, default):\n",
    "                    \"\"\"Determines which augmenters to apply to masks.\"\"\"\n",
    "                    return (augmenter.__class__.__name__ in MASK_AUGMENTERS)\n",
    "\n",
    "                # Store shapes before augmentation to compare\n",
    "                image_shape = image.shape\n",
    "                mask_shape = mask.shape\n",
    "                # Make augmenters deterministic to apply similarly to images and masks\n",
    "                det = augmentation.to_deterministic()\n",
    "                x = det.augment_image(x)\n",
    "                # Change mask to np.uint8 because imgaug doesn't support np.bool\n",
    "                y = det.augment_image(y.astype(np.uint8),\n",
    "                                         hooks=imgaug.HooksImages(activator=hook))\n",
    "            x.append(x_)\n",
    "            y.append(y_)\n",
    "\n",
    "        x_ = np.array(x)\n",
    "        y_ = np.array(y)\n",
    "        yield x_, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_gen(x_test, y_test, crop_size=500, stride=250):\n",
    "    i = 0\n",
    "    while True:\n",
    "        x = []\n",
    "        y = []\n",
    "        for x_start in range(0, crop_size+1, stride):\n",
    "            for y_start in range(0, crop_size+1, stride):\n",
    "                x_crop = x_test[i][x_start:(x_start+crop_size), y_start:(y_start+crop_size), :]\n",
    "                y_crop = y_test[i][x_start:(x_start+crop_size), y_start:(y_start+crop_size), :]\n",
    "                x.append(x_crop)\n",
    "                y.append(y_crop)\n",
    "        i+=1\n",
    "        yield np.array(x), np.array(y)\n",
    "        if i == len(y_test):\n",
    "            i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "def img_combine(img, ncols=5, size=1, path=False):\n",
    "    nimg=len(img)\n",
    "    nrows=int(ceil(nimg/ncols))\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, sharex=True, sharey=True, figsize=(ncols*size,nrows*size))\n",
    "    if nrows==0:\n",
    "        return\n",
    "    elif ncols == 1:\n",
    "        for r, ax in zip(np.arange(nrows), axes):\n",
    "            nth=r\n",
    "            if nth < nimg:\n",
    "                ax.imshow(img[nth], cmap='rainbow')\n",
    "            ax.set_axis_off()\n",
    "    elif nrows==1:\n",
    "        for c, ax in zip(np.arange(ncols), axes):\n",
    "            nth=c\n",
    "            if nth < nimg:\n",
    "                ax.imshow(img[nth], cmap='rainbow' )\n",
    "            ax.set_axis_off()\n",
    "    else:\n",
    "        for r, row in zip(np.arange(nrows), axes):\n",
    "            for c, ax in zip(np.arange(ncols), row):\n",
    "                nth=r*ncols+c\n",
    "                if nth < nimg:\n",
    "                    ax.imshow(img[nth], cmap='rainbow')\n",
    "                ax.set_axis_off()\n",
    "    \n",
    "    if path:\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(path, dpi = 300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(data_gen(x_train, y_train_, 500, 8))\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "plt.subplot(121)\n",
    "plt.imshow(y[0][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(x[0].astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_test_, np.expand_dims(y_test_, 3), batch_size=10,\n",
    "#                     epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_size = 500\n",
    "model = Deeplabv3(input_shape=(crop_size, crop_size, 3), classes=2, OS=8)\n",
    "logits = model.output\n",
    "output = keras.layers.Activation(\"softmax\")(logits)\n",
    "model = Model(model.input, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef_loss(y_true, y_pred, smooth = 1):\n",
    "    def dice_coef_fix(y_true, y_pred):\n",
    "        intersection = K.sum(K.abs(y_true * y_pred), axis = -1)\n",
    "        iou = (2. * intersection + smooth) / (K.sum(K.square(y_true), -1) + K.sum(K.square(y_pred),-1) + smooth)\n",
    "        return iou\n",
    "    loss = 1 - dice_coef_fix(y_true, y_pred)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "early = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, verbose=1)\n",
    "check = keras.callbacks.ModelCheckpoint(monitor=\"val_loss\",\n",
    "                                        filepath=\"/data/jimmy15923/cg_kidney_seg/test.h5\",\n",
    "                                        verbose=1, save_best_only=True)\n",
    "\n",
    "reduce = keras.callbacks.ReduceLROnPlateau(patience=3),\n",
    "model.compile(optimizer=keras.optimizers.SGD(lr=1e-4, momentum=0.9, nesterov=True),\n",
    "              loss='categorical_crossentropy')\n",
    "\n",
    "vgen = val_gen(x_test, y_test_)\n",
    "model.fit_generator(data_gen(x_train, y_train_, crop_size, 12),\n",
    "                    steps_per_epoch=200,\n",
    "                    epochs=10, \n",
    "                    validation_data=vgen,\n",
    "                    validation_steps=len(y_test_)\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplab_v3_plus.model import relu6, BilinearUpsampling\n",
    "from keras.models import load_model\n",
    "deeplab_model = load_model(\"/data/jimmy15923/cg_kidney_seg/test.h5\",\n",
    "                           custom_objects={'relu6':relu6,'BilinearUpsampling':BilinearUpsampling })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=[model.input], outputs=[model.output])\n",
    "model.load_weights('/data/jimmy15923/cg_kidney_seg/test.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgen = val_gen(x_test, y_test_, crop_size=500, stride=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(data_gen(x_train, y_train_, crop_size, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(vgen)\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "y_pred = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_combine(x, ncols=2)\n",
    "img_combine(y[:,:,:,0], ncols=2)\n",
    "img_combine((y_pred[:,:,:,0] > 0.5)*1, ncols=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.choice(len(y))\n",
    "y_show = y_pred[idx][:,:,1]\n",
    "y_show[y_show >= 0.5]*1\n",
    "plt.subplot(121)\n",
    "plt.imshow(y[idx][:,:,0])\n",
    "plt.subplot(122)\n",
    "plt.imshow(y_show.astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(y_pred.squeeze(), -1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0].squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.argmax(y_pred[3].squeeze(), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf18_keras]",
   "language": "python",
   "name": "conda-env-tf18_keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
