{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jimmy15923/.conda/envs/tf18_keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/jimmy15923/.conda/envs/tf18_keras/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1618993340022840639\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 10913166132\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 276994800938331186\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:04:00.0, compute capability: 6.1\"\n",
      "]\n",
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet50\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     4\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        500\n",
      "DETECTION_MIN_CONFIDENCE       0\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 4\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  512\n",
      "IMAGE_MIN_SCALE                2.0\n",
      "IMAGE_RESIZE_MODE              crop\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               400\n",
      "MEAN_PIXEL                     [169.82 117.39 156.07]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           glomerulus\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        2000\n",
      "POST_NMS_ROIS_TRAINING         1000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (8, 16, 32, 64, 128)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.9\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                174\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       None\n",
      "TRAIN_ROIS_PER_IMAGE           128\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               54\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n",
      "Loading weights  /data/jimmy15923/monuseg/maskrcnn/mask_rcnn_coco.h5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import skimage.io as sio\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append('/home/jimmy15923/project/monuseg/Mask_RCNN')  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = \"/data/jimmy15923/monuseg/maskrcnn/mask_rcnn_coco.h5\"\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "# DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "DEFAULT_LOGS_DIR = \"/data/jimmy15923/cg_kidney_seg/logs\"\n",
    "\n",
    "# The dataset doesn't have a standard train/val split, so I picked\n",
    "# a variety of images to surve as a validation set.\n",
    "import glob\n",
    "import random\n",
    "idx = [os.path.basename(x) for x in glob.glob(\"/data/jimmy15923/cg_kidney_seg/train/*\")]\n",
    "random.seed(7)\n",
    "random.shuffle(idx)\n",
    "TRAIN_IMAGE_IDS, VAL_IMAGE_IDS = idx[:700], idx[700:]\n",
    "\n",
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "\n",
    "class KidneyConfig(Config):\n",
    "    \"\"\"Configuration for training on the nucleus segmentation dataset.\"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"glomerulus\"\n",
    "\n",
    "    # number of GPU\n",
    "    GPU_COUNT = 1\n",
    "    \n",
    "    # Adjust depending on your GPU memory\n",
    "    IMAGES_PER_GPU = 4\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + nucleus\n",
    "\n",
    "    # Number of training and validation steps per epoch\n",
    "    STEPS_PER_EPOCH = (918 - len(VAL_IMAGE_IDS)) // IMAGES_PER_GPU\n",
    "    VALIDATION_STEPS = max(1, len(VAL_IMAGE_IDS) // IMAGES_PER_GPU)\n",
    "\n",
    "    # Don't exclude based on confidence. Since we have two classes\n",
    "    # then 0.5 is the minimum anyway as it picks between nucleus and BG\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "\n",
    "    # Backbone network architecture\n",
    "    # Supported values are: resnet50, resnet101\n",
    "    BACKBONE = \"resnet50\"\n",
    "\n",
    "    # Input image resizing\n",
    "    # Random crops of size 512x512\n",
    "    IMAGE_RESIZE_MODE = \"crop\"\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    IMAGE_MIN_SCALE = 2.0\n",
    "\n",
    "    # Length of square anchor side in pixels\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
    "\n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 1000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.90\n",
    "\n",
    "    # How many anchors per image to use for RPN training\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 64 *4\n",
    "\n",
    "    # Image mean (RGB)\n",
    "#     169.82889032142856\n",
    "#     117.38651496428571\n",
    "#     156.06911957142856\n",
    "    MEAN_PIXEL = np.array([169.82, 117.39, 156.07])\n",
    "\n",
    "    # If enabled, resizes instance masks to a smaller size to reduce\n",
    "    # memory load. Recommended when using high-resolution images.\n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "    \n",
    "    # Number of ROIs per image to feed to classifier/mask heads\n",
    "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
    "    # enough positive proposals to fill this and keep a positive:negative\n",
    "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
    "    # the RPN NMS threshold.\n",
    "    TRAIN_ROIS_PER_IMAGE = 128\n",
    "\n",
    "    # Maximum number of ground truth instances to use in one image\n",
    "    MAX_GT_INSTANCES = 400\n",
    "\n",
    "    # Max number of final detections per image\n",
    "    DETECTION_MAX_INSTANCES = 500\n",
    "    \n",
    "    # Use batch normalization\n",
    "    TRAIN_BN = None\n",
    "\n",
    "\n",
    "class KidneyInferenceConfig(KidneyConfig):\n",
    "    # Set batch size to 1 to run one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # Don't resize imager for inferencing\n",
    "    IMAGE_RESIZE_MODE = \"pad64\"\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.75\n",
    "\n",
    "class myKidneyDataset(utils.Dataset):\n",
    "\n",
    "    def load_glomerulus(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the nuclei dataset.\n",
    "        dataset_dir: Root directory of the dataset\n",
    "        subset: Subset to load. Either the name of the sub-directory,\n",
    "                such as stage1_train, stage1_test, ...etc. or, one of:\n",
    "                * train: stage1_train excluding validation images\n",
    "                * val: validation images from VAL_IMAGE_IDS\n",
    "        \"\"\"\n",
    "        # Add classes. We have one class.\n",
    "        # Naming the dataset nucleus, and the class nucleus\n",
    "        self.add_class(\"glomerulus\", 1, \"glomerulus\")\n",
    "\n",
    "        # Which subset?\n",
    "        # \"val\": use hard-coded list above\n",
    "        # \"train\": use data from stage1_train minus the hard-coded list above\n",
    "        # else: use the data from the specified sub-directory\n",
    "        assert subset in [\"train\", \"val\", \"stage1_train\", \"stage1_test\", \"stage2_test\"]\n",
    "\n",
    "        subset_dir = \"train\" if subset in [\"train\", \"val\"] else subset\n",
    "        dataset_dir = os.path.join(dataset_dir, subset_dir)\n",
    "        if subset == \"val\":\n",
    "            image_ids = VAL_IMAGE_IDS\n",
    "        else:\n",
    "            # Get image ids from directory names\n",
    "            image_ids = next(os.walk(dataset_dir))[1]\n",
    "            image_ids.remove(\"S2016-30816_9_0\")\n",
    "            image_ids.remove(\"S2016-30816_9_1\")\n",
    "            if subset == \"train\":\n",
    "                image_ids = list(set(image_ids) - set(VAL_IMAGE_IDS))\n",
    "\n",
    "\n",
    "        # Add images\n",
    "        for image_id in image_ids:\n",
    "            self.add_image(\n",
    "                \"glomerulus\",\n",
    "                image_id=image_id,\n",
    "                path=os.path.join(dataset_dir, image_id, \"image/{}_slide.jpg\".format(image_id)))\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        # Get mask directory from image path\n",
    "        mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"mask\")\n",
    "        # Read mask files from .png image\n",
    "        mask = []\n",
    "        for f in next(os.walk(mask_dir))[2]:\n",
    "            if f.endswith(\".jpg\"):\n",
    "                m = skimage.io.imread(os.path.join(mask_dir, f)).astype(np.bool)\n",
    "                mask.append(m)\n",
    "        mask = np.stack(mask, axis=-1)\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID, we return an array of ones\n",
    "        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"glomerulus\":\n",
    "            return info[\"id\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Training\n",
    "############################################################\n",
    "\n",
    "def train(model, dataset_dir, subset):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = myKidneyDataset()\n",
    "    dataset_train.load_glomerulus(dataset_dir, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = myKidneyDataset()\n",
    "    dataset_val.load_glomerulus(dataset_dir, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # Image augmentation\n",
    "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
    "    augmentation = iaa.SomeOf((0, 2), [\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.OneOf([iaa.Affine(rotate=90),\n",
    "                   iaa.Affine(rotate=180),\n",
    "                   iaa.Affine(rotate=270)]),\n",
    "        iaa.Multiply((0.8, 1.5)),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 5.0)),\n",
    "    ])\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "\n",
    "    # If starting from imagenet, train heads only for a bit\n",
    "    # since they have random weights\n",
    "    print(\"Train network head\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=5,\n",
    "                augmentation=augmentation,\n",
    "                layers='heads')\n",
    "\n",
    "    print(\"Train all layers\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=10,\n",
    "                augmentation=augmentation,\n",
    "                layers='all')\n",
    "\n",
    "############################################################\n",
    "#  Detection\n",
    "############################################################\n",
    "\n",
    "def detect(model, dataset_dir, subset):\n",
    "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
    "    print(\"Running on {}\".format(dataset_dir))\n",
    "\n",
    "    # Create directory\n",
    "    if not os.path.exists(RESULTS_DIR):\n",
    "        os.makedirs(RESULTS_DIR)\n",
    "    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
    "    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\n",
    "    os.makedirs(submit_dir)\n",
    "\n",
    "    # Read dataset\n",
    "    dataset = NucleusDataset()\n",
    "    dataset.load_nucleus(dataset_dir, subset)\n",
    "    dataset.prepare()\n",
    "    # Load over images\n",
    "    submission = []\n",
    "    for image_id in dataset.image_ids:\n",
    "        # Load image and run detection\n",
    "        image = dataset.load_image(image_id)\n",
    "        # Detect objects\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        # Encode image to RLE. Returns a string of multiple lines\n",
    "        source_id = dataset.image_info[image_id][\"id\"]\n",
    "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
    "        submission.append(rle)\n",
    "        # Save image with masks\n",
    "        visualize.display_instances(\n",
    "            image, r['rois'], r['masks'], r['class_ids'],\n",
    "            dataset.class_names, r['scores'],\n",
    "            show_bbox=False, show_mask=False,\n",
    "            title=\"Predictions\")\n",
    "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n",
    "\n",
    "    # Save to csv file\n",
    "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
    "    file_path = os.path.join(submit_dir, \"submit.csv\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(submission)\n",
    "    print(\"Saved to \", submit_dir)\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Command Line\n",
    "############################################################\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     import argparse\n",
    "\n",
    "#     # Parse command line arguments\n",
    "#     parser = argparse.ArgumentParser(\n",
    "#         description='Mask R-CNN for nuclei counting and segmentation')\n",
    "#     parser.add_argument(\"command\",\n",
    "#                         metavar=\"<command>\",\n",
    "#                         help=\"'train' or 'detect'\")\n",
    "#     parser.add_argument('--dataset', required=False,\n",
    "#                         metavar=\"/path/to/dataset/\",\n",
    "#                         help='Root directory of the dataset')\n",
    "#     parser.add_argument('--weights', required=True,\n",
    "#                         metavar=\"/path/to/weights.h5\",\n",
    "#                         help=\"Path to weights .h5 file or 'coco'\")\n",
    "#     parser.add_argument('--logs', required=False,\n",
    "#                         default=DEFAULT_LOGS_DIR,\n",
    "#                         metavar=\"/path/to/logs/\",\n",
    "#                         help='Logs and checkpoints directory (default=logs/)')\n",
    "#     parser.add_argument('--subset', required=False,\n",
    "#                         metavar=\"Dataset sub-directory\",\n",
    "#                         help=\"Subset of dataset to run prediction on\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    # Configurations\n",
    "\n",
    "config = KidneyConfig()\n",
    "\n",
    "config.display()\n",
    "\n",
    "# Create model\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                              model_dir='/data/jimmy15923/cg_kidney_seg/logs/')\n",
    "\n",
    "weights_path = COCO_WEIGHTS_PATH\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "\n",
    "# model.load_weights(weights_path, by_name=True, exclude=[\n",
    "#         \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "#         \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "\n",
    "    # Train or evaluate\n",
    "\n",
    "# train(model, '/data/jimmy15923/cg_kidney_seg/', \"train\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myKidneyDataset(utils.Dataset):\n",
    "\n",
    "    def load_glomerulus(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the nuclei dataset.\n",
    "        dataset_dir: Root directory of the dataset\n",
    "        subset: Subset to load. Either the name of the sub-directory,\n",
    "                such as stage1_train, stage1_test, ...etc. or, one of:\n",
    "                * train: stage1_train excluding validation images\n",
    "                * val: validation images from VAL_IMAGE_IDS\n",
    "        \"\"\"\n",
    "        # Add classes. We have one class.\n",
    "        # Naming the dataset nucleus, and the class nucleus\n",
    "        self.add_class(\"glomerulus\", 1, \"glomerulus\")\n",
    "\n",
    "        # Which subset?\n",
    "        # \"val\": use hard-coded list above\n",
    "        # \"train\": use data from stage1_train minus the hard-coded list above\n",
    "        # else: use the data from the specified sub-directory\n",
    "        assert subset in [\"train\", \"val\", \"stage1_train\", \"stage1_test\", \"stage2_test\"]\n",
    "\n",
    "        subset_dir = \"train\" if subset in [\"train\", \"val\"] else subset\n",
    "        dataset_dir = os.path.join(dataset_dir, subset_dir)\n",
    "        if subset == \"val\":\n",
    "            image_ids = VAL_IMAGE_IDS\n",
    "        else:\n",
    "            # Get image ids from directory names\n",
    "            image_ids = next(os.walk(dataset_dir))[1]\n",
    "            image_ids.remove(\"S2016-30816_9_0\")\n",
    "            image_ids.remove(\"S2016-30816_9_1\")\n",
    "            if subset == \"train\":\n",
    "                image_ids = list(set(image_ids) - set(VAL_IMAGE_IDS))\n",
    "\n",
    "\n",
    "        # Add images\n",
    "        for image_id in image_ids:\n",
    "            self.add_image(\n",
    "                \"glomerulus\",\n",
    "                image_id=image_id,\n",
    "                path=os.path.join(dataset_dir, image_id, \"image/{}_slide.jpg\".format(image_id)))\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        # Get mask directory from image path\n",
    "        mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"mask\")\n",
    "        # Read mask files from .png image\n",
    "        mask = []\n",
    "        for f in next(os.walk(mask_dir))[2]:\n",
    "            if f.endswith(\".jpg\"):\n",
    "                m = skimage.io.imread(os.path.join(mask_dir, f)).astype(np.bool)\n",
    "                mask.append(m)\n",
    "        mask = np.stack(mask, axis=-1)\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID, we return an array of ones\n",
    "        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"glomerulus\":\n",
    "            return info[\"id\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/data/jimmy15923/cg_kidney_seg/'\n",
    "dataset_train = myKidneyDataset()\n",
    "dataset_train.load_glomerulus(dataset_dir, \"train\")\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = myKidneyDataset()\n",
    "dataset_val.load_glomerulus(dataset_dir, \"val\")\n",
    "dataset_val.prepare()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S2016-15757_5_3'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_IMAGE_IDS[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = dataset_train.load_mask(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efeb6ff8e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask[0][:,:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import skimage.io as sio\n",
    "import functools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from tensorflow.python.client import device_lib\n",
    "print (device_lib.list_local_devices())\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.io\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append('/home/jimmy15923/project/monuseg/Mask_RCNN')  # To find local version of the library\n",
    "from mrcnn.config import Config\n",
    "from mrcnn import utils\n",
    "from mrcnn import model as modellib\n",
    "from mrcnn import visualize\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = \"/data/jimmy15923/monuseg/maskrcnn/mask_rcnn_coco.h5\"\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "# DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "DEFAULT_LOGS_DIR = \"/data/jimmy15923/cg_kidney_seg/logs\"\n",
    "\n",
    "# The dataset doesn't have a standard train/val split, so I picked\n",
    "# a variety of images to surve as a validation set.\n",
    "import glob\n",
    "import random\n",
    "idx = [os.path.basename(x) for x in glob.glob(\"/data/jimmy15923/cg_kidney_seg/*\")]\n",
    "random.seed(7)\n",
    "random.shuffle(idx)\n",
    "TRAIN_IMAGE_IDS, VAL_IMAGE_IDS = idx[:700], idx[700:]\n",
    "\n",
    "############################################################\n",
    "#  Configurations\n",
    "############################################################\n",
    "\n",
    "class KidneyConfig(Config):\n",
    "    \"\"\"Configuration for training on the nucleus segmentation dataset.\"\"\"\n",
    "    # Give the configuration a recognizable name\n",
    "    NAME = \"glomerulus\"\n",
    "\n",
    "    # number of GPU\n",
    "    GPU_COUNT = 1\n",
    "    \n",
    "    # Adjust depending on your GPU memory\n",
    "    IMAGES_PER_GPU = 6\n",
    "\n",
    "    # Number of classes (including background)\n",
    "    NUM_CLASSES = 1 + 1  # Background + nucleus\n",
    "\n",
    "    # Number of training and validation steps per epoch\n",
    "    STEPS_PER_EPOCH = (918 - len(VAL_IMAGE_IDS)) // IMAGES_PER_GPU\n",
    "    VALIDATION_STEPS = max(1, len(VAL_IMAGE_IDS) // IMAGES_PER_GPU)\n",
    "\n",
    "    # Don't exclude based on confidence. Since we have two classes\n",
    "    # then 0.5 is the minimum anyway as it picks between nucleus and BG\n",
    "    DETECTION_MIN_CONFIDENCE = 0\n",
    "\n",
    "    # Backbone network architecture\n",
    "    # Supported values are: resnet50, resnet101\n",
    "    BACKBONE = \"resnet50\"\n",
    "\n",
    "    # Input image resizing\n",
    "    # Random crops of size 512x512\n",
    "    IMAGE_RESIZE_MODE = \"crop\"\n",
    "    IMAGE_MIN_DIM = 512\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    IMAGE_MIN_SCALE = 2.0\n",
    "\n",
    "    # Length of square anchor side in pixels\n",
    "    RPN_ANCHOR_SCALES = (8, 16, 32, 64, 128)\n",
    "\n",
    "    # ROIs kept after non-maximum supression (training and inference)\n",
    "    POST_NMS_ROIS_TRAINING = 1000\n",
    "    POST_NMS_ROIS_INFERENCE = 2000\n",
    "\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.90\n",
    "\n",
    "    # How many anchors per image to use for RPN training\n",
    "    RPN_TRAIN_ANCHORS_PER_IMAGE = 64 *4\n",
    "\n",
    "    # Image mean (RGB)\n",
    "#     169.82889032142856\n",
    "#     117.38651496428571\n",
    "#     156.06911957142856\n",
    "    MEAN_PIXEL = np.array([169.82, 117.39, 156.07])\n",
    "\n",
    "    # If enabled, resizes instance masks to a smaller size to reduce\n",
    "    # memory load. Recommended when using high-resolution images.\n",
    "    USE_MINI_MASK = True\n",
    "    MINI_MASK_SHAPE = (56, 56)  # (height, width) of the mini-mask\n",
    "    \n",
    "    # Number of ROIs per image to feed to classifier/mask heads\n",
    "    # The Mask RCNN paper uses 512 but often the RPN doesn't generate\n",
    "    # enough positive proposals to fill this and keep a positive:negative\n",
    "    # ratio of 1:3. You can increase the number of proposals by adjusting\n",
    "    # the RPN NMS threshold.\n",
    "    TRAIN_ROIS_PER_IMAGE = 128\n",
    "\n",
    "    # Maximum number of ground truth instances to use in one image\n",
    "    MAX_GT_INSTANCES = 400\n",
    "\n",
    "    # Max number of final detections per image\n",
    "    DETECTION_MAX_INSTANCES = 500\n",
    "    \n",
    "    # Use batch normalization\n",
    "    TRAIN_BN = None\n",
    "\n",
    "\n",
    "class KidneyInferenceConfig(KidneyConfig):\n",
    "    # Set batch size to 1 to run one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    # Don't resize imager for inferencing\n",
    "    IMAGE_RESIZE_MODE = \"pad64\"\n",
    "    # Non-max suppression threshold to filter RPN proposals.\n",
    "    # You can increase this during training to generate more propsals.\n",
    "    RPN_NMS_THRESHOLD = 0.75\n",
    "\n",
    "class myKidneyDataset(utils.Dataset):\n",
    "\n",
    "    def load_glomerulus(self, dataset_dir, subset):\n",
    "        \"\"\"Load a subset of the nuclei dataset.\n",
    "        dataset_dir: Root directory of the dataset\n",
    "        subset: Subset to load. Either the name of the sub-directory,\n",
    "                such as stage1_train, stage1_test, ...etc. or, one of:\n",
    "                * train: stage1_train excluding validation images\n",
    "                * val: validation images from VAL_IMAGE_IDS\n",
    "        \"\"\"\n",
    "        # Add classes. We have one class.\n",
    "        # Naming the dataset nucleus, and the class nucleus\n",
    "        self.add_class(\"glomerulus\", 1, \"glomerulus\")\n",
    "\n",
    "        # Which subset?\n",
    "        # \"val\": use hard-coded list above\n",
    "        # \"train\": use data from stage1_train minus the hard-coded list above\n",
    "        # else: use the data from the specified sub-directory\n",
    "#         assert subset in [\"train\", \"val\", \"stage1_train\", \"stage1_test\", \"stage2_test\"]\n",
    "\n",
    "#         subset_dir = \"stage1_train\" if subset in [\"train\", \"val\"] else subset\n",
    "#         dataset_dir = os.path.join(dataset_dir, subset_dir)\n",
    "        if subset == \"val\":\n",
    "            image_ids = VAL_IMAGE_IDS\n",
    "        else:\n",
    "            # Get image ids from directory names\n",
    "            image_ids = next(os.walk(dataset_dir))[1]\n",
    "            if subset == \"train\":\n",
    "                image_ids = list(set(image_ids) - set(VAL_IMAGE_IDS))\n",
    "\n",
    "\n",
    "        # Add images\n",
    "        for image_id in image_ids:\n",
    "            self.add_image(\n",
    "                \"glomerulus\",\n",
    "                image_id=image_id,\n",
    "                path=os.path.join(dataset_dir, image_id, \"images/{}.jpg\".format(image_id)))\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "       Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with\n",
    "            one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        # Get mask directory from image path\n",
    "        mask_dir = os.path.join(os.path.dirname(os.path.dirname(info['path'])), \"mask\")\n",
    "        # Read mask files from .png image\n",
    "        mask = []\n",
    "        for f in next(os.walk(mask_dir))[2]:\n",
    "            if f.endswith(\".jpg\"):\n",
    "                m = skimage.io.imread(os.path.join(mask_dir, f)).astype(np.bool)\n",
    "                mask.append(m)\n",
    "        mask = np.stack(mask, axis=-1)\n",
    "        # Return mask, and array of class IDs of each instance. Since we have\n",
    "        # one class ID, we return an array of ones\n",
    "        return mask, np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the path of the image.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        if info[\"source\"] == \"glomerulus\":\n",
    "            return info[\"id\"]\n",
    "        else:\n",
    "            super(self.__class__, self).image_reference(image_id)\n",
    "\n",
    "\n",
    "dataset_dir = '/data/jimmy15923/cg_kidney_seg/'\n",
    "\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Training\n",
    "############################################################\n",
    "\n",
    "def train(model, dataset_dir, subset):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = myKidneyDataset()\n",
    "    dataset_train.load_glomerulus(dataset_dir, \"train\")\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = myKidneyDataset()\n",
    "    dataset_val.load_glomerulus(dataset_dir, \"val\")\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # Image augmentation\n",
    "    # http://imgaug.readthedocs.io/en/latest/source/augmenters.html\n",
    "    augmentation = iaa.SomeOf((0, 2), [\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.OneOf([iaa.Affine(rotate=90),\n",
    "                   iaa.Affine(rotate=180),\n",
    "                   iaa.Affine(rotate=270)]),\n",
    "        iaa.Multiply((0.8, 1.5)),\n",
    "        iaa.GaussianBlur(sigma=(0.0, 5.0)),\n",
    "    ])\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "\n",
    "    # If starting from imagenet, train heads only for a bit\n",
    "    # since they have random weights\n",
    "    print(\"Train network head\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=5,\n",
    "                augmentation=augmentation,\n",
    "                layers='heads')\n",
    "\n",
    "    print(\"Train all layers\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=10,\n",
    "                augmentation=augmentation,\n",
    "                layers='all')\n",
    "\n",
    "############################################################\n",
    "#  Detection\n",
    "############################################################\n",
    "\n",
    "def detect(model, dataset_dir, subset):\n",
    "    \"\"\"Run detection on images in the given directory.\"\"\"\n",
    "    print(\"Running on {}\".format(dataset_dir))\n",
    "\n",
    "    # Create directory\n",
    "    if not os.path.exists(RESULTS_DIR):\n",
    "        os.makedirs(RESULTS_DIR)\n",
    "    submit_dir = \"submit_{:%Y%m%dT%H%M%S}\".format(datetime.datetime.now())\n",
    "    submit_dir = os.path.join(RESULTS_DIR, submit_dir)\n",
    "    os.makedirs(submit_dir)\n",
    "\n",
    "    # Read dataset\n",
    "    dataset = NucleusDataset()\n",
    "    dataset.load_nucleus(dataset_dir, subset)\n",
    "    dataset.prepare()\n",
    "    # Load over images\n",
    "    submission = []\n",
    "    for image_id in dataset.image_ids:\n",
    "        # Load image and run detection\n",
    "        image = dataset.load_image(image_id)\n",
    "        # Detect objects\n",
    "        r = model.detect([image], verbose=0)[0]\n",
    "        # Encode image to RLE. Returns a string of multiple lines\n",
    "        source_id = dataset.image_info[image_id][\"id\"]\n",
    "        rle = mask_to_rle(source_id, r[\"masks\"], r[\"scores\"])\n",
    "        submission.append(rle)\n",
    "        # Save image with masks\n",
    "        visualize.display_instances(\n",
    "            image, r['rois'], r['masks'], r['class_ids'],\n",
    "            dataset.class_names, r['scores'],\n",
    "            show_bbox=False, show_mask=False,\n",
    "            title=\"Predictions\")\n",
    "        plt.savefig(\"{}/{}.png\".format(submit_dir, dataset.image_info[image_id][\"id\"]))\n",
    "\n",
    "    # Save to csv file\n",
    "    submission = \"ImageId,EncodedPixels\\n\" + \"\\n\".join(submission)\n",
    "    file_path = os.path.join(submit_dir, \"submit.csv\")\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(submission)\n",
    "    print(\"Saved to \", submit_dir)\n",
    "\n",
    "\n",
    "############################################################\n",
    "#  Command Line\n",
    "############################################################\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    # Parse command line arguments\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Mask R-CNN for nuclei counting and segmentation')\n",
    "    parser.add_argument(\"command\",\n",
    "                        metavar=\"<command>\",\n",
    "                        help=\"'train' or 'detect'\")\n",
    "    parser.add_argument('--dataset', required=False,\n",
    "                        metavar=\"/path/to/dataset/\",\n",
    "                        help='Root directory of the dataset')\n",
    "    parser.add_argument('--weights', required=True,\n",
    "                        metavar=\"/path/to/weights.h5\",\n",
    "                        help=\"Path to weights .h5 file or 'coco'\")\n",
    "    parser.add_argument('--logs', required=False,\n",
    "                        default=DEFAULT_LOGS_DIR,\n",
    "                        metavar=\"/path/to/logs/\",\n",
    "                        help='Logs and checkpoints directory (default=logs/)')\n",
    "    parser.add_argument('--subset', required=False,\n",
    "                        metavar=\"Dataset sub-directory\",\n",
    "                        help=\"Subset of dataset to run prediction on\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Validate arguments\n",
    "    if args.command == \"train\":\n",
    "        assert args.dataset, \"Argument --dataset is required for training\"\n",
    "    elif args.command == \"detect\":\n",
    "        assert args.subset, \"Provide --subset to run prediction on\"\n",
    "\n",
    "    print(\"Weights: \", args.weights)\n",
    "    print(\"Dataset: \", args.dataset) \n",
    "    if args.subset:\n",
    "        print(\"Subset: \", args.subset)\n",
    "    print(\"Logs: \", args.logs)\n",
    "\n",
    "    # Configurations\n",
    "    if args.command == \"train\":\n",
    "        config = myNucleusConfig()\n",
    "    else:\n",
    "        config = myNucleusInferenceConfig()\n",
    "    config.display()\n",
    "\n",
    "    # Create model\n",
    "    if args.command == \"train\":\n",
    "        model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "    else:\n",
    "        model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                                  model_dir=args.logs)\n",
    "\n",
    "    # Select weights file to load\n",
    "    if args.weights.lower() == \"coco\":\n",
    "        weights_path = COCO_WEIGHTS_PATH\n",
    "        # Download weights file\n",
    "        if not os.path.exists(weights_path):\n",
    "            utils.download_trained_weights(weights_path)\n",
    "    elif args.weights.lower() == \"last\":\n",
    "        # Find last trained weights\n",
    "        weights_path = model.find_last()\n",
    "    elif args.weights.lower() == \"imagenet\":\n",
    "        # Start from ImageNet trained weights\n",
    "        weights_path = model.get_imagenet_weights()\n",
    "    else:\n",
    "        weights_path = args.weights\n",
    "\n",
    "    # Load weights\n",
    "    print(\"Loading weights \", weights_path)\n",
    "    if args.weights.lower() == \"coco\":\n",
    "        # Exclude the last layers because they require a matching\n",
    "        # number of classes\n",
    "        model.load_weights(weights_path, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "    else:\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    # Train or evaluate\n",
    "    if args.command == \"train\":\n",
    "        train(model, args.dataset, args.subset)\n",
    "    elif args.command == \"detect\":\n",
    "        detect(model, args.dataset, args.subset)\n",
    "    else:\n",
    "        print(\"'{}' is not recognized. \"\n",
    "              \"Use 'train' or 'detect'\".format(args.command))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tf18_keras]",
   "language": "python",
   "name": "conda-env-tf18_keras-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
